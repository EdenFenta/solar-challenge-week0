{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995e8212",
   "metadata": {},
   "source": [
    "# 1, Imports & display settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d010548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d07cc2",
   "metadata": {},
   "source": [
    "# 2, Load raw CSV and sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61876234",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = \"../data/benin.csv\"\n",
    "if not os.path.exists(raw_path):\n",
    "    raise FileNotFoundError(f\"{raw_path} not found. Place raw CSV in data/\")\n",
    "\n",
    "df = pd.read_csv(raw_path)\n",
    "\n",
    "print(\"shape:\", df.shape)\n",
    "display(df.head())\n",
    "display(df.tail())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eb52b6",
   "metadata": {},
   "source": [
    "# 3, Parse Timestamp, convert dtypes, and check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f7bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "\n",
    "n_bad_ts = df['Timestamp'].isna().sum()\n",
    "print(f\"Bad/missing timestamps: {n_bad_ts}\")\n",
    "\n",
    "if n_bad_ts > 0:\n",
    "    display(df[df['Timestamp'].isna()].head())\n",
    "\n",
    "df = df.sort_values('Timestamp').reset_index(drop=True)\n",
    "df = df.set_index('Timestamp')\n",
    "\n",
    "dups = df.index.duplicated().sum()\n",
    "print(f\"Duplicate timestamp rows: {dups}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4b2c6",
   "metadata": {},
   "source": [
    "# 4, Summary statistics & missing-value report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_desc = df.describe().T\n",
    "display(num_desc)\n",
    "\n",
    "missing = df.isna().sum().to_frame('n_missing')\n",
    "missing['pct_missing'] = missing['n_missing'] / len(df) * 100\n",
    "missing = missing.sort_values('pct_missing', ascending=False)\n",
    "display(missing)\n",
    "\n",
    "cols_above_5pct = missing[missing['pct_missing'] > 5].index.tolist()\n",
    "print(\"Columns with >5% missing:\", cols_above_5pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d577432",
   "metadata": {},
   "source": [
    "# 5, Initial cleaning: drop empty columns and obvious fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12faf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Comments' in df.columns and df['Comments'].isna().all():\n",
    "    df = df.drop(columns=['Comments'])\n",
    "    print(\"Dropped Comments column (all empty).\")\n",
    "\n",
    "if 'Cleaning' in df.columns:\n",
    "    df['Cleaning'] = pd.to_numeric(df['Cleaning'], errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8583ef2",
   "metadata": {},
   "source": [
    "# 6, Handle physically impossible values (negatives for irradiance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27644c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "irr_cols = [c for c in ['GHI','DNI','DHI'] if c in df.columns]\n",
    "\n",
    "for c in irr_cols:\n",
    "    nneg = (df[c] < 0).sum()\n",
    "    if nneg > 0:\n",
    "        print(f\"{c}: {nneg} negative values -> set to NaN\")\n",
    "        df.loc[df[c] < 0, c] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3b354c",
   "metadata": {},
   "source": [
    "# 7, Z-score outlier detection for target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7207a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_z = [c for c in ['GHI','DNI','DHI','ModA','ModB','WS','WSgust'] if c in df.columns]\n",
    "\n",
    "z_df = df[cols_to_z].copy()\n",
    "z_scores = z_df.apply(lambda x: np.abs(stats.zscore(x.dropna())), axis=0)\n",
    "\n",
    "outlier_mask = pd.DataFrame(False, index=df.index, columns=cols_to_z)\n",
    "for c in cols_to_z:\n",
    "    col = df[c]\n",
    "    z = (col - col.mean())/col.std(ddof=0)\n",
    "    outlier_mask.loc[z.abs() > 3, c] = True\n",
    "\n",
    "outlier_counts = outlier_mask.sum().to_frame('n_outliers')\n",
    "outlier_counts['pct_outliers'] = outlier_counts['n_outliers'] / len(df) * 100\n",
    "display(outlier_counts.sort_values('pct_outliers', ascending=False))\n",
    "\n",
    "rows_flagged = outlier_mask.any(axis=1).sum()\n",
    "print(f\"Rows flagged as outlier in any monitored column: {rows_flagged}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80a9762",
   "metadata": {},
   "source": [
    "# 8, Apply cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da844fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_cols = [c for c in ['GHI','DNI','DHI','ModA','ModB','TModA','TModB','WS','WSgust'] if c in df.columns]\n",
    "\n",
    "for c in impute_cols:\n",
    "    med = df[c].median()\n",
    "    n_missing_before = df[c].isna().sum()\n",
    "    df[c] = df[c].fillna(med)\n",
    "    n_missing_after = df[c].isna().sum()\n",
    "    print(f\"{c}: median={med}; missing before={n_missing_before}, after={n_missing_after}\")\n",
    "\n",
    "multi_outliers = outlier_mask.sum(axis=1)\n",
    "drop_rows = multi_outliers[multi_outliers >= 2].index\n",
    "print(f\"Rows with outliers in >=2 columns: {len(drop_rows)}\")\n",
    "if len(drop_rows) > 0 and len(drop_rows) < 5000:\n",
    "    df = df.drop(index=drop_rows)\n",
    "    print(f\"Dropped {len(drop_rows)} rows due to multiple outlier flags.\")\n",
    "else:\n",
    "    print(\"Not dropping multi-outlier rows (too many or none); they are left after imputation).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191e508f",
   "metadata": {},
   "source": [
    "# 9, Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481082de",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)\n",
    "clean_path = \"data/benin_clean.csv\"\n",
    "df.to_csv(clean_path, index=True)\n",
    "print(\"Saved cleaned file to:\", clean_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6faa36b",
   "metadata": {},
   "source": [
    "# 10, Time features and resampling for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df['hour'] = df.index.hour\n",
    "df['month'] = df.index.month\n",
    "df['date'] = df.index.date\n",
    "\n",
    "expected_numeric = ['GHI','DNI','DHI','ModA','ModB','Tamb','TModA','TModB',\n",
    "                    'RH','WS','WSgust','WSstdev','WD','WDstdev','BP','Precipitation']\n",
    "for c in expected_numeric:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "daily = df[numeric_cols].resample('D').mean()\n",
    "hourly = df.groupby('hour')[numeric_cols].mean()\n",
    "\n",
    "print(\"daily.shape:\", daily.shape, \"hourly.shape:\", hourly.shape)\n",
    "display(daily[['GHI','DNI','DHI','Tamb']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a5846",
   "metadata": {},
   "source": [
    "# 11, Time series plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_plot = [c for c in ['GHI','DNI','DHI','Tamb'] if c in df.columns]\n",
    "daily[cols_plot].plot(subplots=False, figsize=(14,5))\n",
    "plt.title('Daily average: ' + ', '.join(cols_plot))\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43382860",
   "metadata": {},
   "source": [
    "# 12, Diurnal (hourly) pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f206a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_cols = [c for c in ['GHI','DNI','DHI'] if c in df.columns]\n",
    "hourly[hourly_cols].plot(figsize=(10,5))\n",
    "plt.title('Average by hour of day')\n",
    "plt.xlabel('Hour (0-23)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca17b2f5",
   "metadata": {},
   "source": [
    "# 13, Cleaning impact: ModA & ModB pre/post cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06012cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Cleaning' in df.columns and 'ModA' in df.columns and 'ModB' in df.columns:\n",
    "    grouped = df.groupby('Cleaning')[['ModA','ModB']].mean()\n",
    "    display(grouped)\n",
    "    grouped.plot(kind='bar')\n",
    "    plt.title('Average ModA & ModB by Cleaning flag')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cleaning or module columns missing; skipping this step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d8bd51",
   "metadata": {},
   "source": [
    "# 14, Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d603fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_cols = [c for c in ['GHI','DNI','DHI','ModA','ModB','TModA','TModB','Tamb','RH','BP'] if c in df.columns]\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df[corr_cols].corr(), annot=True, fmt=\".2f\", cmap='coolwarm', center=0)\n",
    "plt.title('Correlation heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af40db07",
   "metadata": {},
   "source": [
    "# 15, Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WS vs GHI\n",
    "if 'WS' in df.columns and 'GHI' in df.columns:\n",
    "    plt.scatter(df['WS'], df['GHI'], alpha=0.2)\n",
    "    plt.xlabel('WS (m/s)'); plt.ylabel('GHI (W/m2)')\n",
    "    plt.title('Wind Speed vs GHI'); plt.show()\n",
    "\n",
    "# RH vs Tamb\n",
    "if 'RH' in df.columns and 'Tamb' in df.columns:\n",
    "    plt.scatter(df['RH'], df['Tamb'], alpha=0.2)\n",
    "    plt.xlabel('RH (%)'); plt.ylabel('Tamb (°C)')\n",
    "    plt.title('Relative Humidity vs Ambient Temp'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3dbcaa",
   "metadata": {},
   "source": [
    "# 16, Wind rose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if set(['WD','WS']).issubset(df.columns):\n",
    "    wd = df['WD'].dropna()\n",
    "    ws = df['WS'].dropna()\n",
    "    # use WD to bin directions and show counts\n",
    "    wd_rad = np.deg2rad(wd)\n",
    "    bins = 16\n",
    "    counts, edges = np.histogram(wd_rad, bins=bins)\n",
    "    angles = (edges[:-1] + edges[1:]) / 2\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    ax.bar(angles, counts, width=(2*np.pi)/bins)\n",
    "    plt.title('Wind direction (counts) - polar histogram')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"WD or WS missing; skipping wind rose.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d03e1c",
   "metadata": {},
   "source": [
    "# 17, Bubble chart: GHI vs Tamb (size = RH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if set(['GHI','Tamb','RH']).issubset(df.columns):\n",
    "    s = (df['RH'] - df['RH'].min()) / (df['RH'].max() - df['RH'].min()) * 200 + 10\n",
    "    plt.scatter(df['Tamb'], df['GHI'], s=s, alpha=0.1)\n",
    "    plt.xlabel('Tamb (°C)'); plt.ylabel('GHI (W/m2)')\n",
    "    plt.title('GHI vs Tamb (bubble size ~ RH)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"GHI/Tamb/RH missing; skipping bubble chart.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a9d359",
   "metadata": {},
   "source": [
    "# 18, Export summary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987fb006",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df[['GHI','DNI','DHI']].agg(['mean', 'median', 'std']).T\n",
    "summary.to_csv('data/benin_summary_table.csv')\n",
    "display(summary)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
